# Proyecto 2: Sistema de Clasificaci√≥n de Animales con CNN

## üìå Descripci√≥n
Este proyecto implementa un sistema completo de clasificaci√≥n de im√°genes de animales utilizando Redes Neuronales Convolucionales (CNN). El sistema incluye herramientas de preprocesamiento (redimensionamiento y rotaci√≥n de im√°genes), entrenamiento de un modelo de deep learning, y un m√≥dulo de prueba para clasificar nuevas im√°genes en cinco categor√≠as de animales.

## üéØ Objetivos
- Implementar un pipeline completo de visi√≥n por computadora: preprocesamiento, entrenamiento y evaluaci√≥n
- Crear herramientas para aumentar datasets mediante rotaci√≥n de im√°genes
- Entrenar una CNN capaz de clasificar 5 categor√≠as de animales
- Desarrollar un sistema modular con scripts espec√≠ficos para cada tarea
- Evaluar el rendimiento del modelo con m√©tricas precisas y visualizaciones

## üõ†Ô∏è Tecnolog√≠as Utilizadas
- **Lenguaje:** Python 3.x
- **Librer√≠as:** TensorFlow, Keras, OpenCV, NumPy, Matplotlib, scikit-learn, scikit-image, PIL
- **Arquitectura:** CNN con m√∫ltiples capas convolucionales y fully connected
- **Tama√±o de imagen:** 28x21 p√≠xeles (formato retrato)
- **Categor√≠as:** 5 clases de animales (gato, hormiga, mariquita, perro, tortuga)

## üöÄ Instalaci√≥n y Ejecuci√≥n

### Prerrequisitos
```bash
pip install tensorflow keras opencv-python numpy matplotlib scikit-learn scikit-image pillow
```

### Estructura del Proyecto
```
datasets/                    # Dataset original organizado por categor√≠as
datasets_resized/           # Im√°genes redimensionadas autom√°ticamente
models/                     # Modelos entrenados guardados
imagenes/                   # Im√°genes para rotaci√≥n (opcional)
resultados/                 # Im√°genes rotadas generadas
```

### Flujo de Ejecuci√≥n Recomendado:

#### Paso 1: Redimensionar Im√°genes del Dataset
```bash
python resize.py
```
- **Funci√≥n:** Redimensiona todas las im√°genes a 28x21 p√≠xeles
- **Entrada:** `datasets/` con subcarpetas por animal
- **Salida:** `datasets_resized/` con estructura mantenida
- **Par√°metros:** Tama√±o fijo (28,21) con interpolaci√≥n AREA

#### Paso 2: Aumentar Dataset con Rotaciones (Opcional)
```bash
python rotar.py
```
- **Funci√≥n:** Genera 360 rotaciones por imagen (1¬∞ a 360¬∞)
- **Entrada:** `imagenes/` con im√°genes a rotar
- **Salida:** `resultados/` con todas las rotaciones
- **Par√°metros:** Expand=True para evitar recorte

#### Paso 3: Entrenar el Modelo CNN
```bash
python cnn.py
```
- **Funci√≥n:** Entrena la CNN con el dataset redimensionado
- **Entrada:** `datasets_resized/` organizado por categor√≠as
- **Salida:** Modelo guardado en `models/riesgo.h5`
- **Par√°metros:** 40 √©pocas, batch_size=64, learning_rate=0.001

#### Paso 4: Probar el Modelo con Nuevas Im√°genes
```bash
python prueba.py
```
- **Funci√≥n:** Clasifica im√°genes nuevas usando el modelo entrenado
- **Entrada:** Archivos especificados en el c√≥digo (ej: mariquita6.jpg)
- **Salida:** Nombre del archivo y categor√≠a predicha
- **Formato:** `nombre_imagen clase_predicha`

## üìä Metodolog√≠a

### 1. Preprocesamiento de Datos (resize.py)
- **Lectura recursiva:** Todas las im√°genes en estructura jer√°rquica
- **Redimensionamiento uniforme:** 28x21 p√≠xeles (alto x ancho)
- **Interpolaci√≥n AREA:** Adecuada para reducci√≥n de tama√±o
- **Preservaci√≥n de estructura:** Mantiene organizaci√≥n por carpetas/categor√≠as

### 2. Aumento de Datos (rotar.py)
- **Rotaci√≥n completa:** 360 rotaciones por imagen (1¬∞ incrementos)
- **Expand=True:** La imagen no se recorta, ajusta tama√±o del canvas
- **Generaci√≥n masiva:** Crea dataset expandido para mejor generalizaci√≥n
- **Organizaci√≥n √∫nica:** Todas las rotaciones en una sola carpeta

### 3. Entrenamiento CNN (cnn.py)
**Arquitectura de la red:**
1. **Capa Convolucional 1:** 32 filtros 3x3, LeakyReLU, MaxPooling 2x2, Dropout 50%
2. **Capa Convolucional 2:** 64 filtros 3x3, LeakyReLU, MaxPooling 2x2, Dropout 50%
3. **Capa Convolucional 3:** 128 filtros 3x3, LeakyReLU, MaxPooling 2x2, Dropout 50%
4. **Capas Fully Connected:**
   - Flatten (aplanamiento)
   - Dense 32 neuronas, LeakyReLU, Dropout 50%
   - Dense 5 neuronas (softmax para 5 clases)

**Proceso de entrenamiento:**
- **Divisi√≥n de datos:** 80% entrenamiento, 20% prueba
- **Validaci√≥n:** 20% del entrenamiento para monitoreo
- **Normalizaci√≥n:** Valores de p√≠xeles escalados a [0, 1]
- **One-hot encoding:** Etiquetas categ√≥ricas a formato vectorial
- **Optimizaci√≥n:** SGD con learning_rate=0.001
- **Funci√≥n de p√©rdida:** Categorical Crossentropy

### 4. Evaluaci√≥n y Visualizaci√≥n
- **Gr√°ficos de m√©tricas:** Accuracy y Loss durante entrenamiento/validaci√≥n
- **Predicciones correctas/incorrectas:** Grids 3x3 con ejemplos visuales
- **Reporte de clasificaci√≥n:** Precision, recall, f1-score por clase
- **Guardado autom√°tico:** Modelo en formato H5 para reutilizaci√≥n

### 5. Inferencia (prueba.py)
- **Carga de modelo:** Modelo H5 preentrenado
- **Preprocesamiento:** Mismo redimensionamiento (28x21) y normalizaci√≥n
- **Predicci√≥n:** Softmax para probabilidades por clase
- **Resultado:** Muestra la clase con mayor probabilidad

## üñºÔ∏è Evidencias
![prueba](https://github.com/user-attachments/assets/67854224-c78f-4df6-94a6-db520a50b9ed)
